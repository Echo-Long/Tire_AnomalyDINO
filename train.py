import os
import torch
import numpy as np
import gc  # å¯¼å…¥åƒåœ¾å›æ”¶æ¨¡å—
from pathlib import Path
from PIL import Image

# -------------------------- å…³é”®ï¼šå…¨å±€æŒ‡å®šç¼“å­˜/ä¸´æ—¶æ–‡ä»¶åˆ°æ•°æ®ç›˜ --------------------------
os.environ['TORCH_HOME'] = "/root/autodl-tmp/.cache/torch"
os.environ['LIGHTNING_LOGS'] = "/root/autodl-tmp/lightning_logs"
os.environ['TMPDIR'] = "/root/autodl-tmp/tmp"
# åˆ›å»ºä¸´æ—¶ç›®å½•
Path("/root/autodl-tmp/tmp").mkdir(exist_ok=True, parents=True)
Path("/root/autodl-tmp/.cache/torch").mkdir(exist_ok=True, parents=True)

# -------------------------- åŸºç¡€é…ç½® --------------------------
from anomalib.models.components.dinov2.dinov2_loader import DinoV2Loader
def fixed_get_weight_path(self, model_type, architecture, patch_size):
    return Path("/root/autodl-tmp/.cache/torch/hub/checkpoints/dinov2_vits14_pretrain.pth")
DinoV2Loader._get_weight_path = fixed_get_weight_path
print("âœ… å·²å¼ºåˆ¶è¦†ç›–DinoV2Loaderçš„æƒé‡è·¯å¾„è®¡ç®—é€»è¾‘")

torch.set_float32_matmul_precision('medium')

# -------------------------- æ ¸å¿ƒè·¯å¾„é…ç½® --------------------------
TRAIN_ROOT = "/root/autodl-tmp/Tire/PatchCore_Dataset_512x512_20px_augmented"
MODEL_SAVE_ROOT = Path("/root/autodl-tmp/Tire/AnomalyDINO/trained_models")
IMAGE_SIZE = (512, 512)
BLOCK_IDS = [1,2,3,4,5]

# -------------------------- è®¾å¤‡é…ç½® --------------------------
if torch.cuda.is_available():
    GPU_INDEX = 0
    DEVICE = torch.device(f"cuda:{GPU_INDEX}")
    torch.cuda.set_device(GPU_INDEX)
    print(f"ã€è®¾å¤‡ä¿¡æ¯ã€‘ä½¿ç”¨GPUï¼šcuda:{GPU_INDEX} | åç§°ï¼š{torch.cuda.get_device_name(GPU_INDEX)}")
else:
    DEVICE = torch.device("cpu")
    print("ã€è®¾å¤‡ä¿¡æ¯ã€‘ä½¿ç”¨CPUï¼ˆæ— å¯ç”¨GPUï¼‰")

MODEL_SAVE_ROOT.mkdir(exist_ok=True, parents=True)

# -------------------------- æ•°æ®é¢„å¤„ç†é…ç½® --------------------------
from anomalib.pre_processing import PreProcessor
from torchvision.transforms.v2 import Compose, Resize, ToTensor, Normalize

custom_transform = Compose([
    Resize(size=IMAGE_SIZE),
    ToTensor(),
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])
custom_pre_processor = PreProcessor(transform=custom_transform)

# -------------------------- å¾ªç¯è®­ç»ƒ5ä¸ªblockçš„æ¨¡å‹ --------------------------
from anomalib.data import Folder
from anomalib.data.utils import TestSplitMode, ValSplitMode
from anomalib.models.image.anomaly_dino.lightning_model import AnomalyDINO
from lightning.pytorch import Trainer
from lightning.pytorch.callbacks import ModelCheckpoint
import shutil

# æ¸…ç†æ—§çš„Lightningæ—¥å¿—
lightning_logs_path = Path("/root/autodl-tmp/lightning_logs")
if lightning_logs_path.exists():
    shutil.rmtree(lightning_logs_path)
print("âœ… å·²æ¸…ç†æ—§çš„Lightningæ—¥å¿—")

for block_id in BLOCK_IDS:
    print(f"\n" + "="*50)
    print(f"å¼€å§‹è®­ç»ƒ Block {block_id} çš„æ¨¡å‹")
    print("="*50)
    
    # 1. åŠ¨æ€è·¯å¾„ï¼ˆæ¯ä¸ªblockå®Œå…¨ç‹¬ç«‹ï¼‰
    TRAIN_NORMAL_ROOT = f"{TRAIN_ROOT}/tire_block{block_id}/train"
    MODEL_SAVE_DIR = MODEL_SAVE_ROOT / f"model_block{block_id}"
    TMP_CKPT_DIR = MODEL_SAVE_DIR / "tmp_ckpt"
    MODEL_SAVE_DIR.mkdir(exist_ok=True, parents=True)
    
    # 2. æ ·æœ¬æ ¡éªŒ
    good_dir = f"{TRAIN_NORMAL_ROOT}/good"
    if not os.path.exists(good_dir):
        raise ValueError(f"Block {block_id} çš„æ­£å¸¸æ ·æœ¬ç›®å½•ä¸å­˜åœ¨ï¼š{good_dir}")
    normal_sample_count = len([f for f in os.listdir(good_dir) if f.endswith(('.png','.jpg','.jpeg'))])
    print(f"ã€æ ·æœ¬æ ¡éªŒã€‘Block {block_id} æ­£å¸¸æ ·æœ¬æ•°ï¼š{normal_sample_count}")
    assert normal_sample_count > 0, f"Block {block_id} æ­£å¸¸æ ·æœ¬æ•°ä¸èƒ½ä¸º0ï¼"
    
    # 3. æ„å»ºDataModule
    datamodule = Folder(
        name=f"tire_anomaly_block{block_id}",
        root=TRAIN_NORMAL_ROOT,
        normal_dir="good",
        abnormal_dir="",
        normal_split_ratio=0.0,
        test_split_mode=TestSplitMode.FROM_DIR,
        val_split_mode=ValSplitMode.FROM_TEST,
        val_split_ratio=0.0,
        train_batch_size=8,
        eval_batch_size=1,
        num_workers=1,
        augmentations=custom_pre_processor,
        extensions=(".png", ".jpg", ".jpeg"),
    )
    datamodule.setup()
    
    # 4. åˆå§‹åŒ–æ¨¡å‹
    model = AnomalyDINO(
        num_neighbours=1,
        encoder_name="dinov2_vit_small_14",
        masking=False,
        coreset_subsampling=False,
        sampling_ratio=0.1,
        pre_processor=custom_pre_processor,
        post_processor=True,
    )
    model.save_hyperparameters(ignore=['pre_processor'])
    model = model.to(DEVICE)
    print(f"âœ… Block {block_id} æ¨¡å‹å·²è¿ç§»åˆ°ç›®æ ‡è®¾å¤‡")
    
    # 5. é…ç½®ModelCheckpoint
    checkpoint_callback = ModelCheckpoint(
        dirpath=TMP_CKPT_DIR,
        filename=f"block{block_id}",
        save_top_k=0,
        save_last=False,
        save_on_train_epoch_end=False,
        enable_version_counter=False,
    )
    
    # 6. åˆå§‹åŒ–Trainer
    trainer = Trainer(
        accelerator="cuda" if torch.cuda.is_available() else "cpu",
        devices=[GPU_INDEX] if torch.cuda.is_available() else 1,
        gradient_clip_val=0,
        max_epochs=1,
        num_sanity_val_steps=0,
        enable_model_summary=False,
        default_root_dir="/root/autodl-tmp/lightning_logs",
        callbacks=[checkpoint_callback],
        enable_checkpointing=True,
    )
    
    # 7. è®­ç»ƒ
    print(f"\nã€Block {block_id}ã€‘å¼€å§‹æ„å»ºæ­£å¸¸æ ·æœ¬ç‰¹å¾åº“")
    trainer.fit(model=model, datamodule=datamodule)
    
    # 8. ä¿å­˜æ¨¡å‹ï¼ˆå…³é”®ï¼šä¿å­˜åˆ°ç¡¬ç›˜ï¼Œåç»­å¯åŠ è½½ï¼‰
    try:
        memory_bank = model.model.memory_bank.to(DEVICE, non_blocking=True)
        print(f"âœ… Block {block_id} ç‰¹å¾åº“æ„å»ºæˆåŠŸï¼å°ºå¯¸ï¼š{memory_bank.shape} | è®¾å¤‡ï¼š{memory_bank.device}")
        assert memory_bank.shape[0] > 0, f"Block {block_id} ç‰¹å¾åº“ä¸ºç©ºï¼"
        
        # ä¿å­˜åˆ°ç¡¬ç›˜ï¼ˆè¿™ä¸€æ­¥æ˜¯â€œä¿ç•™æ¨¡å‹â€çš„æ ¸å¿ƒï¼Œæ–‡ä»¶ä¸ä¼šè¢«åˆ é™¤ï¼‰
        model_save_path = MODEL_SAVE_DIR / f"anomalydino_tire_model_block{block_id}.pth"
        torch.save({
            "model_state_dict": model.state_dict(),
            "memory_bank": memory_bank,
            "pre_processor": custom_pre_processor,
            "image_size": IMAGE_SIZE,
            "block_id": block_id
        }, model_save_path)
        print(f"âœ… Block {block_id} æ¨¡å‹å·²ä¿å­˜åˆ°ï¼š{model_save_path}")
        
        # æ¸…ç†ä¸´æ—¶ç›®å½•
        if TMP_CKPT_DIR.exists():
            shutil.rmtree(TMP_CKPT_DIR)
            
    except Exception as e:
        raise RuntimeError(f"âŒ Block {block_id} ç‰¹å¾åº“æ„å»º/ä¿å­˜å¤±è´¥ï¼š{e}")
    
    # -------------------------- æ ¸å¿ƒä¿®æ”¹ï¼šæ¸…ç†æ˜¾å­˜ï¼ˆä¸åˆ é™¤ç¡¬ç›˜æ¨¡å‹æ–‡ä»¶ï¼‰ --------------------------
    if torch.cuda.is_available():
        # 1. åˆ é™¤å½“å‰Blockçš„å†…å­˜å®ä¾‹ï¼ˆæ¨¡å‹ã€æ•°æ®ã€è®­ç»ƒå™¨ï¼‰â€”â€” é‡Šæ”¾Pythonå¼•ç”¨
        del model, datamodule, trainer, memory_bank
        # 2. å¼ºåˆ¶åƒåœ¾å›æ”¶ï¼ˆå›æ”¶Pythonå±‚é¢çš„å†…å­˜ï¼‰
        gc.collect()
        # 3. æ¸…ç©ºGPUç¼“å­˜ï¼ˆé‡Šæ”¾æ˜¾å­˜ï¼‰
        torch.cuda.empty_cache()
        # éªŒè¯æ˜¾å­˜é‡Šæ”¾æƒ…å†µï¼ˆå¯é€‰ï¼Œç”¨äºè°ƒè¯•ï¼‰
        free_mem = torch.cuda.get_device_properties(DEVICE).total_memory - torch.cuda.memory_allocated(DEVICE)
        print(f"âœ… Block {block_id} æ˜¾å­˜å·²æ¸…ç† | é‡Šæ”¾åç©ºé—²æ˜¾å­˜ï¼š{free_mem / 1024**3:.2f} GB")
    else:
        del model, datamodule, trainer, memory_bank
        gc.collect()
        print(f"âœ… Block {block_id} å†…å­˜å·²æ¸…ç†")

# æ¸…ç†å…¨å±€ä¸´æ—¶æ–‡ä»¶
if lightning_logs_path.exists():
    shutil.rmtree(lightning_logs_path)

print("\n" + "="*50)
print("ğŸ‰ æ‰€æœ‰5ä¸ªBlockçš„æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
print(f"æ¨¡å‹ä¿å­˜æ ¹ç›®å½•ï¼š{MODEL_SAVE_ROOT}")
print("="*50)